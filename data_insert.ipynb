{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "create_table_queries = [\n",
    "    '''\n",
    "    CREATE TABLE Products (\n",
    "        product_key INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        product_id VARCHAR(100) NOT NULL UNIQUE,\n",
    "        product_category VARCHAR(100),\n",
    "        product_name_length INT,\n",
    "        product_description_length INT,\n",
    "        product_photos_qty INT,\n",
    "        product_weight_g FLOAT,\n",
    "        product_length_cm FLOAT,\n",
    "        product_height_cm FLOAT,\n",
    "        product_width_cm FLOAT,\n",
    "        price DECIMAL(10, 2),\n",
    "        freight_value DECIMAL(10, 2)\n",
    "    );\n",
    "    ''',\n",
    "\n",
    "    '''\n",
    "    CREATE TABLE Locations (\n",
    "        location_key INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        zip_code CHAR(5),\n",
    "        city VARCHAR(50),\n",
    "        state CHAR(2)\n",
    "    );\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE GeoLocations (\n",
    "        geolocation_key INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        latitude DECIMAL(10, 6),\n",
    "        longitude DECIMAL(10, 6),\n",
    "        location_key INT,\n",
    "        FOREIGN KEY (location_key) REFERENCES Locations(location_key)\n",
    "    );\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE Customers (\n",
    "        customer_key INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        customer_unique_id VARCHAR(100) NOT NULL UNIQUE,\n",
    "        location_key INT,\n",
    "        FOREIGN KEY (location_key) REFERENCES Locations(location_key)\n",
    "    );\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE Sellers (\n",
    "        seller_key INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        seller_id VARCHAR(100) NOT NULL UNIQUE,\n",
    "        location_key INT,\n",
    "        FOREIGN KEY (location_key) REFERENCES Locations(location_key)\n",
    "    );\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE Orders (\n",
    "        order_key INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        order_id VARCHAR(100) NOT NULL UNIQUE,\n",
    "        customer_key INT,\n",
    "        order_status VARCHAR(25),\n",
    "        order_purchase_date DATETIME,\n",
    "        order_approved_date DATETIME,\n",
    "        order_delivered_carrier_date DATETIME,\n",
    "        order_delivered_customer_date DATETIME,\n",
    "        order_estimated_delivery_date DATETIME,\n",
    "        FOREIGN KEY (customer_key) REFERENCES Customers(customer_key)\n",
    "    );\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE Payments (\n",
    "        payments_key INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        order_key INT,\n",
    "        payment_type VARCHAR(25),\n",
    "        payment_installments INT,\n",
    "        payment_value DECIMAL(10, 2),\n",
    "        FOREIGN KEY (order_key) REFERENCES Orders(order_key)\n",
    "    );\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE OrderItems (\n",
    "        order_items_key INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        order_key INT,\n",
    "        product_key INT,\n",
    "        seller_key INT,\n",
    "        qty INT,\n",
    "        unit_price DECIMAL(10, 2),\n",
    "        total_price DECIMAL(10, 2),\n",
    "        FOREIGN KEY (order_key) REFERENCES Orders(order_key),\n",
    "        FOREIGN KEY (product_key) REFERENCES Products(product_key),\n",
    "        FOREIGN KEY (seller_key) REFERENCES Sellers(seller_key)\n",
    "    );\n",
    "    '''\n",
    "]\n",
    "\n",
    "# For Database connection\n",
    "def dbconn():\n",
    "    # conn = pymysql.connect(\n",
    "    #     host='mysql.clarksonmsda.org', \n",
    "    #     user='vempatd', \n",
    "    #     password='welcome123', \n",
    "    #     db='vempatd_bigdata_final_project', \n",
    "    #     port=3306\n",
    "    # )\n",
    "    config = yaml.safe_load(Path(\"config.yml\").read_text())\n",
    "\n",
    "    conn = pymysql.connect(host=config['db']['host'], port=config['db']['port'], user=config['db']['user'],\n",
    "                       passwd=config['db']['passwd'], db=config['db']['db'], autocommit=True)\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    return conn, cur\n",
    "\n",
    "# For dropping and creating tables\n",
    "def create_tables():\n",
    "    conn, cur = dbconn()\n",
    "    try:\n",
    "        # Dropping tables if exist\n",
    "        tables = [\n",
    "            'OrderItems', 'Payments', 'Orders', 'Sellers', \n",
    "            'Customers', 'GeoLocations', 'Locations', \n",
    "            'Products'\n",
    "        ]\n",
    "        for table in tables:\n",
    "            cur.execute(f'DROP TABLE IF EXISTS {table};')\n",
    "        \n",
    "        # Creating tables\n",
    "        for query in create_table_queries:\n",
    "            cur.execute(query)\n",
    "        conn.commit()\n",
    "        print(\"Tables created successfully.\")\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error creating tables: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_locations_and_geolocation(geo_file):\n",
    "    conn, cur = dbconn()\n",
    "    try:\n",
    "        with open(geo_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            \n",
    "            # To track unique zip codes for Locations\n",
    "            unique_zip = {}\n",
    "            geolocation_data = []\n",
    "\n",
    "            for row in reader:\n",
    "                zip_code = row['geolocation_zip_code_prefix']\n",
    "                city = row['geolocation_city']\n",
    "                state = row['geolocation_state']\n",
    "                latitude = float(row['geolocation_lat'])\n",
    "                longitude = float(row['geolocation_lng'])\n",
    "\n",
    "                if zip_code not in unique_zip:\n",
    "                    unique_zip[zip_code] = (city, state)\n",
    "\n",
    "                geolocation_data.append((zip_code, latitude, longitude))\n",
    "\n",
    "            # Inserting unique locations into Locations\n",
    "            insert_location_data_sql = '''\n",
    "                    INSERT INTO Locations (zip_code, city, state)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                '''\n",
    "            location_batch = []\n",
    "            for zip_code, (city, state) in unique_zip.items():\n",
    "                location_batch.append((zip_code, city, state))\n",
    "                if len(location_batch) == 5000:\n",
    "                    cur.executemany(insert_location_data_sql, location_batch)\n",
    "                    conn.commit()\n",
    "                    location_batch = []\n",
    "            \n",
    "            if location_batch:\n",
    "                cur.executemany(insert_location_data_sql, location_batch)\n",
    "                conn.commit()\n",
    "\n",
    "            print(f\"Inserted data into Locations.\")\n",
    "\n",
    "            # Retrieving location keys for GeoLocations\n",
    "            location_map = {}\n",
    "            cur.execute('SELECT zip_code, location_key FROM Locations')\n",
    "            for zip_code, location_key in cur.fetchall():\n",
    "                location_map[zip_code] = location_key\n",
    "\n",
    "            # Inserting data into GeoLocations using location_key\n",
    "            insert_geo_loc_data_sql = '''\n",
    "                    INSERT INTO GeoLocations (latitude, longitude, location_key)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                '''\n",
    "            geolocation_batch = []\n",
    "            for zip_code, latitude, longitude in geolocation_data:\n",
    "                location_key = location_map.get(zip_code)\n",
    "                geolocation_batch.append((latitude, longitude, location_key))\n",
    "                if len(geolocation_batch) == 25000:\n",
    "                    cur.executemany(insert_geo_loc_data_sql, geolocation_batch)\n",
    "                    conn.commit()\n",
    "                    geolocation_batch = []\n",
    "\n",
    "            if geolocation_batch:\n",
    "                cur.executemany(insert_geo_loc_data_sql, geolocation_batch)\n",
    "                conn.commit()\n",
    "            print(f\"Inserted data into GeoLocations.\")\n",
    "\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error processing geolocation data: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def insert_products(product_file, order_items_file):\n",
    "    conn, cur = dbconn()\n",
    "    try:\n",
    "        product_price_mapping = defaultdict(lambda: {'price': 0.0, 'freight_value': 0.0})\n",
    "        \n",
    "        with open(order_items_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                product_id = row['product_id']\n",
    "                price = float(row['price']) if row['price'] else 0.0\n",
    "                freight_value = float(row['freight_value']) if row['freight_value'] else 0.0\n",
    "\n",
    "                product_price_mapping[product_id]['price'] += price\n",
    "                product_price_mapping[product_id]['freight_value'] += freight_value\n",
    "        with open(product_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            product_data = []\n",
    "            for row in reader:\n",
    "                product_id = row['product_id']\n",
    "                product_category = row['product category'] if row['product category'] else None\n",
    "                product_name_length = row['product_name_length'] if row['product_name_length'] else None\n",
    "                product_description_length = row['product_description_length'] if row['product_description_length'] else None\n",
    "                product_photos_qty = row['product_photos_qty'] if row['product_photos_qty'] else None\n",
    "                product_weight_g = row['product_weight_g'] if row['product_weight_g'] else None\n",
    "                product_length_cm = row['product_length_cm'] if row['product_length_cm'] else None\n",
    "                product_height_cm = row['product_height_cm'] if row['product_height_cm'] else None\n",
    "                product_width_cm = row['product_width_cm'] if row['product_width_cm'] else None\n",
    "\n",
    "                price = product_price_mapping[product_id]['price']\n",
    "                freight_value = product_price_mapping[product_id]['freight_value']\n",
    "                \n",
    "\n",
    "                product_data.append((product_id, product_category, product_name_length, product_description_length, product_photos_qty, product_weight_g,\n",
    "                                     product_length_cm, product_height_cm, product_width_cm, price, freight_value))\n",
    "\n",
    "                if len(product_data) == 5000:\n",
    "                    insert_product_sql = '''\n",
    "                        INSERT INTO Products (product_id, product_category, product_name_length, product_description_length, product_photos_qty, product_weight_g,\n",
    "                                     product_length_cm, product_height_cm, product_width_cm, price, freight_value)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    '''\n",
    "                    cur.executemany(insert_product_sql, product_data)\n",
    "                    conn.commit()\n",
    "                    product_data = []\n",
    "\n",
    "            if product_data:\n",
    "                cur.executemany(insert_product_sql, product_data)\n",
    "                conn.commit()\n",
    "\n",
    "        print(\"Inserted Products data into Products table.\")\n",
    "\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error inserting product data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mapping(table_name, id, key):\n",
    "    conn, cur = dbconn()\n",
    "    try:\n",
    "        query = f\"SELECT {id}, {key} FROM {table_name}\"\n",
    "        cur.execute(query)\n",
    "        column_names = [desc[0] for desc in cur.description]\n",
    "        rows = [dict(zip(column_names, row)) for row in cur.fetchall()]\n",
    "        return {row[id]: row[key] for row in rows}\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_and_map_customers(customer_file, zip_and_locationKey_mapping):\n",
    "    conn, cur = dbconn()\n",
    "    # zip_and_locationKey_mapping = zip_locationKey_mapping()\n",
    "    customer_id_to_customer_key = {}\n",
    "\n",
    "    try:\n",
    "        with open(customer_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            customer_data = []\n",
    "            unique_customers = {}\n",
    "            customer_id_and_unique_customer_id_mapping = {}\n",
    "\n",
    "            for row in reader:\n",
    "                customer_id = row['customer_id']\n",
    "                customer_unique_id = row['customer_unique_id']\n",
    "                customer_zip_code_prefix = row['customer_zip_code_prefix']\n",
    "                location_key = zip_and_locationKey_mapping.get(customer_zip_code_prefix)\n",
    "\n",
    "                customer_id_and_unique_customer_id_mapping[customer_id] = customer_unique_id\n",
    "\n",
    "                if customer_unique_id not in unique_customers:\n",
    "                    unique_customers[customer_unique_id] = location_key\n",
    "                    customer_data.append((customer_unique_id, location_key))\n",
    "\n",
    "                if len(customer_data) == 25000:\n",
    "                    insert_customer_sql = '''\n",
    "                        INSERT INTO Customers (customer_unique_id, location_key)\n",
    "                        VALUES (%s, %s)\n",
    "                    '''\n",
    "                    cur.executemany(insert_customer_sql, customer_data)\n",
    "                    conn.commit()\n",
    "                    customer_data = []\n",
    "\n",
    "            if customer_data:\n",
    "                insert_customer_sql = '''\n",
    "                    INSERT INTO Customers (customer_unique_id, location_key)\n",
    "                    VALUES (%s, %s)\n",
    "                '''\n",
    "                cur.executemany(insert_customer_sql, customer_data)\n",
    "                conn.commit()\n",
    "\n",
    "        print(\"Inserted customer data into Customers table.\")\n",
    "\n",
    "        cur.execute('SELECT customer_unique_id, customer_key FROM Customers')\n",
    "        unique_customer_key_mapping = dict(cur.fetchall())\n",
    "\n",
    "        for customer_id, customer_unique_id in customer_id_and_unique_customer_id_mapping.items():\n",
    "            customer_key = unique_customer_key_mapping.get(customer_unique_id)\n",
    "            if customer_key:\n",
    "                customer_id_to_customer_key[customer_id] = customer_key\n",
    "            else:\n",
    "                print(f\"No key found for customer_unique_id: {customer_unique_id}\")\n",
    "\n",
    "        print(\"customer_id to customer_key mapping successful.\")\n",
    "        return customer_id_to_customer_key\n",
    "\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error processing customer data: {e}\")\n",
    "        return {}  # Return empty mapping on error\n",
    "\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "def insert_orders(orders_file, customer_id_to_customer_key):\n",
    "    conn, cur = dbconn()\n",
    "    try:\n",
    "        with open(orders_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            order_data = []\n",
    "            for row in reader:\n",
    "                order_id = row['order_id']\n",
    "                customer_id = row['customer_id']\n",
    "                order_status = row['order_status']\n",
    "                def validate_date(date_str):\n",
    "                    if not date_str or date_str.strip() == '':\n",
    "                        return None\n",
    "                    try:\n",
    "                        parsed_date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "                        return parsed_date\n",
    "                    except ValueError:\n",
    "                        return None\n",
    "\n",
    "                order_purchase_date = validate_date(row['order_purchase_timestamp'])\n",
    "                order_approved_date = validate_date(row['order_approved_at'])\n",
    "                order_delivered_carrier_date = validate_date(row['order_delivered_carrier_date'])\n",
    "                order_delivered_customer_date = validate_date(row['order_delivered_customer_date'])\n",
    "                order_estimated_delivery_date = validate_date(row['order_estimated_delivery_date'])\n",
    "                customer_key = customer_id_to_customer_key.get(customer_id)\n",
    "\n",
    "                if customer_key:\n",
    "                    order_data.append((customer_key, order_id, order_status, order_purchase_date, order_approved_date, order_delivered_carrier_date,\n",
    "                                       order_delivered_customer_date, order_estimated_delivery_date))\n",
    "\n",
    "                if len(order_data) == 25000:\n",
    "                    insert_order_sql = '''\n",
    "                        INSERT INTO Orders (customer_key, order_id, order_status, order_purchase_date, order_approved_date, order_delivered_carrier_date,\n",
    "                                       order_delivered_customer_date, order_estimated_delivery_date)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    '''\n",
    "                    cur.executemany(insert_order_sql, order_data)\n",
    "                    conn.commit()\n",
    "                    order_data = []\n",
    "\n",
    "            if order_data:\n",
    "                cur.executemany(insert_order_sql, order_data)\n",
    "                conn.commit()\n",
    "\n",
    "        print(\"Inserted orders into Orders table.\")\n",
    "\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error inserting orders: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sellers(seller_file, zip_and_locationKey_mapping):\n",
    "    conn, cur = dbconn()\n",
    "    # zip_and_locationKey_mapping = zip_locationKey_mapping()\n",
    "    try:\n",
    "        with open(seller_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            seller_data = []\n",
    "            missing_location_records = []\n",
    "            unique_missing_zip = {}\n",
    "            pending_seller_records = []\n",
    "            for row in reader:\n",
    "                seller_id = row['seller_id']\n",
    "                seller_zip_code_prefix = row['seller_zip_code_prefix']\n",
    "                seller_city = row['seller_city']\n",
    "                seller_state = row['seller_state']\n",
    "                location_key = zip_and_locationKey_mapping.get(seller_zip_code_prefix, None)\n",
    "\n",
    "                if location_key:\n",
    "                    seller_data.append((seller_id, location_key))\n",
    "\n",
    "                else:\n",
    "                    if seller_zip_code_prefix not in unique_missing_zip:\n",
    "                        unique_missing_zip[seller_zip_code_prefix] = (seller_city, seller_state)\n",
    "                        for seller_zip_code_prefix, (seller_city, seller_state) in unique_missing_zip.items():\n",
    "                            missing_location_records.append((seller_zip_code_prefix, seller_state, seller_state))\n",
    "                    pending_seller_records.append((seller_id, seller_zip_code_prefix))\n",
    "\n",
    "                if len(seller_data) == 1000:\n",
    "                    insert_seller_sql = '''\n",
    "                        INSERT INTO Sellers (seller_id, location_key)\n",
    "                        VALUES (%s, %s)\n",
    "                    '''\n",
    "                    cur.executemany(insert_seller_sql, seller_data)\n",
    "                    conn.commit()\n",
    "                    seller_data = []\n",
    "\n",
    "            if seller_data:\n",
    "                cur.executemany(insert_seller_sql, seller_data)\n",
    "                conn.commit()\n",
    "\n",
    "        # Handling missing locations\n",
    "        if missing_location_records:\n",
    "\n",
    "            insert_missing_location_sql = '''\n",
    "                INSERT INTO Locations (zip_code, city, state)\n",
    "                VALUES (%s, %s, %s)\n",
    "            '''\n",
    "            cur.executemany(insert_missing_location_sql, missing_location_records)\n",
    "            conn.commit()\n",
    "\n",
    "            # Fetching new location keys for the inserted zip codes\n",
    "            cur.execute('SELECT zip_code, location_key FROM Locations WHERE zip_code IN %s', (tuple(unique_missing_zip),))\n",
    "            new_zip_locationKey_mapping = dict(cur.fetchall())\n",
    "\n",
    "            # Updating the original mapping with the new entries\n",
    "            zip_and_locationKey_mapping.update(new_zip_locationKey_mapping)\n",
    "\n",
    "            # Inserting sellers with newly fetched location keys\n",
    "            new_seller_data = [\n",
    "                (seller_id, zip_and_locationKey_mapping[seller_zip_code_prefix])\n",
    "                for seller_id, seller_zip_code_prefix in pending_seller_records\n",
    "            ]\n",
    "            cur.executemany(insert_seller_sql, new_seller_data)\n",
    "            conn.commit()\n",
    "\n",
    "        print(\"Inserted Seller data into Sellers table.\")\n",
    "\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Error inserting seller data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_payments(payments_file, order_id_to_order_key):\n",
    "    conn, cur = dbconn()\n",
    "    try:\n",
    "        with open(payments_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            payments_data = []\n",
    "            processed_data = {}\n",
    "\n",
    "            for row in reader:\n",
    "                order_id = row['order_id']\n",
    "                payment_type = row['payment_type']\n",
    "                payment_sequential = row['payment_sequential']\n",
    "                installments = int(row['payment_installments']) if row['payment_installments'] else 0\n",
    "                payment_value = float(row['payment_value']) if row['payment_value'] else 0.0\n",
    "\n",
    "                # Using a tuple, combination of (order_id, payment_sequential) as the key\n",
    "                key = (order_id, payment_sequential)\n",
    "\n",
    "                if key not in processed_data:\n",
    "                    processed_data[key] = {\n",
    "                        'payment_type': payment_type,\n",
    "                        'installments': installments,\n",
    "                        'payment_value': payment_value,\n",
    "                    }\n",
    "                else:\n",
    "                    processed_data[key]['installments'] += installments\n",
    "                    processed_data[key]['payment_value'] += payment_value\n",
    "\n",
    "            for (order_id, payment_sequential), values in processed_data.items():\n",
    "                order_key = order_id_to_order_key.get(order_id)\n",
    "                if order_key:\n",
    "                    payments_data.append((\n",
    "                        order_key,\n",
    "                        values['payment_type'],\n",
    "                        values['installments'],\n",
    "                        values['payment_value']\n",
    "                    ))\n",
    "\n",
    "            insert_payments_query = \"\"\"\n",
    "                INSERT INTO Payments (order_key, payment_type, payment_installments, payment_value)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cur.executemany(insert_payments_query, payments_data)\n",
    "            conn.commit()\n",
    "            print(f\"Successfully inserted payments data into Payments.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def insert_order_items(order_items_file, order_id_to_order_key, product_id_to_product_key, seller_id_to_seller_key):\n",
    "    conn, cur = dbconn()\n",
    "    try:\n",
    "        with open(order_items_file, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            order_items_data = []\n",
    "            processed_data = defaultdict(lambda: {'qty': 0, 'unit_price': 0, 'total_price': 0})\n",
    "            \n",
    "            for row in reader:               \n",
    "                order_id = row['order_id']\n",
    "                product_id = row['product_id']\n",
    "                seller_id = row['seller_id']\n",
    "                price = float(row['price']) if row['price'] else 0.0\n",
    "                freight_value = float(row['freight_value']) if row['freight_value'] else 0.0\n",
    "                # Generating a unique key with combination of (order_id, product_id)\n",
    "                key = (order_id, product_id)\n",
    "                \n",
    "                processed_data[key]['qty'] += 1\n",
    "                unit_price = price + freight_value\n",
    "                processed_data[key]['price'] = price\n",
    "                processed_data[key]['freight_value'] = freight_value\n",
    "                processed_data[key]['unit_price'] = unit_price\n",
    "                processed_data[key]['total_price'] = processed_data[key]['qty'] * unit_price\n",
    "                processed_data[key]['seller_id'] = seller_id\n",
    "\n",
    "            order_items_data = []\n",
    "            # product_info = {}\n",
    "            for (order_id, product_id), values in processed_data.items():\n",
    "                seller_key = seller_id_to_seller_key.get(values['seller_id'], None)\n",
    "                product_key = product_id_to_product_key.get(product_id, None)\n",
    "                order_key = order_id_to_order_key.get(order_id, None)\n",
    "                if order_key and product_key and seller_key:\n",
    "                    order_items_data.append((\n",
    "                        order_key, product_key, seller_key,\n",
    "                        values['unit_price'], values['qty'], values['total_price']\n",
    "                    ))\n",
    "                # if product_key:\n",
    "                #     product_info.append((values['price'], values['freight_value'], product_id))\n",
    "\n",
    "            insert_order_items_query = \"\"\"\n",
    "                INSERT INTO OrderItems (order_key, product_key, seller_key, unit_price, qty, total_price)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cur.executemany(insert_order_items_query, order_items_data)\n",
    "            conn.commit()\n",
    "\n",
    "            # update_product_details_in_Products_query = \"\"\"\n",
    "            #     UPDATE Products\n",
    "            #     SET\n",
    "            #     price = %s,\n",
    "            #     freight_value = %s\n",
    "            #     WHERE product_key = %s\n",
    "            # \"\"\"\n",
    "            # cur.executemany(update_product_details_in_Products_query, product_info)\n",
    "            # conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    geo_file = 'geolocation.csv'\n",
    "    products_file = 'products.csv'\n",
    "    customers_file = 'customers.csv'\n",
    "    sellers_file = 'sellers.csv'\n",
    "    orders_file = 'orders.csv'\n",
    "    order_items_file = 'order_items.csv'\n",
    "    payments_file = 'payments.csv'\n",
    "\n",
    "    create_tables()\n",
    "    insert_locations_and_geolocation(geo_file)\n",
    "    insert_products(products_file, order_items_file)\n",
    "    zipcode_to_location_key = extract_mapping(\"Locations\", \"zip_code\", \"location_key\")\n",
    "    customer_id_to_customer_key = insert_and_map_customers(customers_file, zipcode_to_location_key)\n",
    "    insert_orders(orders_file, customer_id_to_customer_key)\n",
    "    insert_sellers(sellers_file, zipcode_to_location_key)\n",
    "    order_id_to_order_key = extract_mapping(\"Orders\", \"order_id\", \"order_key\")\n",
    "    insert_payments(payments_file, order_id_to_order_key)\n",
    "    product_id_to_product_key = extract_mapping(\"Products\", \"product_id\", \"product_key\")\n",
    "    seller_id_to_seller_key = extract_mapping(\"Sellers\", \"seller_id\", \"seller_key\")\n",
    "    insert_order_items(order_items_file, order_id_to_order_key, product_id_to_product_key, seller_id_to_seller_key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully.\n",
      "Inserted data into Locations.\n",
      "Inserted data into GeoLocations.\n",
      "Inserted Products data into Products table.\n",
      "Inserted customer data into Customers table.\n",
      "customer_id to customer_key mapping successful.\n",
      "Inserted orders into Orders table.\n",
      "Inserted Seller data into Sellers table.\n",
      "Successfully inserted payments data into Payments.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
